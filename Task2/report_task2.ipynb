{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Learning Based Strategy for Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athena has various strategies for making a final prediction based on the predictions of the ensemble of weak defenses. These strategies are relatively basic, and leave a large potential for optimization using a neural network. Our strategy involves running the predictions of the ensemble through a neural network trained to make a final prediction based on the predictions of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outline of our approach is as follows:\n",
    "1. Generate subset of benign samples and labels for training and validation\n",
    "2. Collect predictions from the ensemble for training and validation\n",
    "3. Train model with ensemble predictions and confirm data fitting\n",
    "4. Evaluate model on adversarial examples\n",
    "5. Compare results with other avaliable strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step was taken in order to seperate test data and training data, and to avoid over-fitting the model on any particular data. The benign samples were not part of the comparison and final results, removing any bias in the dataset. Labels were saved immediately, while the samples went through further processing\n",
    "**Total training data: 8000**\n",
    "**Total validation data: 2000**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant files\n",
    "- Data Configurations (benign samples and subsamples): configs/experiment/data-mnist.json\n",
    "- Subsampling: learning_based_strategy/utils/data.py\n",
    "- Subset Generated in: learning_based_strategy/collect_raws.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data set *Data Configurations*: bs_file, label_file\n",
    "- Subsamples output directory *Data Configurations*: training_dir\n",
    "- Subsample output *Data Configurations*: training_labels_file, validation_labels_file\n",
    "- Subsample ratio: 80% training, 20%, (ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collect Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model, we need the predictions of each of the weak defenses used. We take the raw predictions, which is a list of ten float values each corresponding to the confidence in it's respective index being the correct value for the image. Since this data is not categorical, it is much easier to process for the network. The raw predictions are gathered for training and validation, and saved to their respective files.<br> <br>**An important note:** This design requires the usage of a fixed number of weak defenses, specified in the *transformation configurations file*, in this experiment we used the first 30 weak defenses supplied by Athena. These were chosen as a way to maximize the number of weak defenses without pushing the limits of our hardware. We wanted to use as many weak defenses as possible to guage the ability of the model to use their respective predictions, in hopes that more information would increase the effectiveness of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Configurations: configs/experiment/data-mnist.json\n",
    "- Athena Ensemble Configuration: configs/experiment/athena-mnist.json\n",
    "- WD Model Configurations: configs/experiment/model-mnist.json\n",
    "- Raw predictions generated in: learning_based_strategy/collect_raws.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weak defenses *Athena configuration*: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating our dataset, we are ready to train the model. But first we will go over the model design:<br>\n",
    "<br>\n",
    "**Model Design**<br>\n",
    "The model is sequential, has 1 input and 1 output layer, as well as 3 hidden layers. The input of the weak defenses is flattened to be one dimensional: *num_wds*x*10*. The number of weak defenses is passed as a parameter to the model, allowing this architecture to be used with any number of weak defenses. This was mostly for ease of testing the code, however it does allow for customization should the experiment be reproduced. A mixture of *tanh* and *relu* activations are used, however since the input and output are both (0,1), this could be changed potentially for better results. The loss function is sparse categorical crossentropy in order to generate an integer from numerical data, the length 10 output layer specifically.\n",
    "<br><br>\n",
    "**Training**<br>\n",
    "The model is trained on the previously collected raw predictions, comparing to the correct label values. We used 10 epochs with a batch size of 100. We found this to be a good middle ground, as a smaller batch size would not allow the model to find minima, and more epochs would push it out of minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neural network design and training: learning_based_strategy/models/nn.py\n",
    "- Neural network saved to: learning_based_strategy/learning-strategy-nn.h5\n",
    "- Parse training data and send for training: learning_based_strategy/train_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input shape: num_wds * 10\n",
    "- Output shape: 10 (sparse categorical gets 1 integer)\n",
    "- Activations: tanh (input) relu (hidden) sigmoid (output)\n",
    "- Epochs: 10\n",
    "- Batch Size: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Model on Adversarial Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was evaluated on all the adversarial examples provided with Athena. In order to do this properly, each AE file was subsampled with the Label file, and the AE's were tested on all relevant models (more on this in the next section). After all predictions were made and results stored, the next AE file was loaded, and a new subsample generated with the label file. While not every AE file had the same exact subsample, the importance of the experiment was to guage the effectiveness of the model as a strategy for Athena. Speaking of, a new ENSEMBLE_STRATEGY was created within Athena which would take the raw predictions of the ensemble and pass them to the previously trained model for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation of models: learning_based_strategy/test_benign_training.py\n",
    "- Subsampling: learning_based_strategy/utils/data.py\n",
    "- Athena: learning_based_strategy/models/athena.py\n",
    "- Model: learning_based_strategy/learning-strategy-nn.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sampling ratio: 20% of AE's from each file used ratio=0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compare Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps 4. and 5. occur simultaneously (almost). For every AE file and it's respectively generated subset, the Undefended Model, Athena Ensemble using AVEP and the same 30 weak defenses used to train the learning based strategy, Athena using Learning based strategy, and PGD-ADT made predictions, and results were gathered. Each AE type has it's own output file containing the results from each variation of that AE (all error rates of the models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation: learning_based_strategy/test_benign_training.py\n",
    "- Data configurations (contain AE's): configs/experiment/data-mnist.json\n",
    "- Output specifications: configs/experiment/results.json\n",
    "- Output directory: learning_based_strategy/results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Plots Generated with learning_based_strategy/generate_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table> <tr>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/fgsm.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/bim_ord2.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/bim_ordinf.png\" width=\"400\"/> </td>\n",
    "</tr> </table>\n",
    "<table> <tr>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/cw_l2.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/deepfool_l2.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/jsma.png\" width=\"400\"/> </td>\n",
    "</tr> </table>\n",
    "<table> <tr>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/pgd.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/mim.png\" width=\"400\"/> </td>\n",
    "    <td> <img src=\"../src/learning_based_strategy/results/onepixel.png\" width=\"400\"/> </td>\n",
    "</tr> </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above can be seen the error rate of each model on each attack type, and each variant of that attack type. In general, the learning based strategy outperforms the other models for low degrees of pertubation; ie lower epsilon values. There are some anomalies, for example JSMA and CW where the learning based strategy *appears* to become better with higher pertubation, however it is unclear what could be causing this. All models seem to perform extremely poorly on deepfool, even on lower levels of pertubation. For onepixel and FGSM, the ensemble is superior, and in FGSM PGD-ADT is the best. On all the other attack types besides ones discussed, the learning based strategy sticks roughly next to the ensemble in terms of error rate, and both having lower error rates than PGD-ADT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of a learning based strategy for Athena appears to offer a small advantage in certain scenarios and specific attack types, low levels of pertubation for example. In general the predictions of weak defenses provide an advantage to no defense or PGD-ADT (at least this configuration of weak defenses, and not against FGSM). One problem could be the loss of semantic meaning of the data in the model. The data from the weak defenses is getting all mixed together, and there may not be much of a way to truly find a pattern in this data. Using more weak defenses would be ideal, however the issue still stands with loss of information in the training data. One solution could be to seperate input layers by weak defense, allowing each weak defense's prediction to be individually processed before being concatenated. Other activations should be tested, preferably sigmoid in order to match the data input and output type as this may improve performance. Using 8000 training samples may also not be enough to truly train the model fully; a full 60k dataset would be ideal (or at least a percentage). Final remarks are related to the potential of using adversarial examples to train the model; if samples were slightly pertubed for training, at least a portion, this would certainly allow the model to determine a pattern in weak defense input. This introduces the issue of over-fitting, but a large and varied dataset should be able to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributions:\n",
    "- Approach: Miles Ziemer, Max Corbel, Shuge Lei, Safi Hoque\n",
    "- Code: Miles Ziemer, Max Corbel\n",
    "- Data gathering: Miles Ziemer\n",
    "- Testing and interpretation/validation of results: Miles Ziemer, Max Corbel, Shuge Lei Safi Hoque\n",
    "- Report: Miles Ziemer, Max Corbel, Shuge Lei, Safi Hoque"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

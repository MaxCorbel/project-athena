{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Learning Based Strategy for Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athena has various strategies for making a final prediction based on the predictions of the ensemble of weak defenses. These strategies are relatively basic, and leave a large potential for optimization using a neural network. Our strategy involves running the predictions of the ensemble through a neural network trained to make a final prediction based on the predictions of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Rundown of Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate data set\n",
    "    1. Need to gather test and training data\n",
    "        - must be uniformly distributed to eliminate bias\n",
    "        - data must be adversarial examples from Athena\n",
    "        - need the proper labels for each example\n",
    "        - need raw predictions from each weak defense for each adversarial example\n",
    "2. Create Neural Network\n",
    "    1. Train a CNN on training data\n",
    "        - Input will be nx10, where n is the number of weak defenses\n",
    "        - Error produced by comparison with 1x10 array in the form [0,0,0,0,x,0,0,0,0,0], where x is the prediction\n",
    "        - Output is the predicted label for the image\n",
    "    2. Implement into Athena\n",
    "        - NN will be a specific strategy that Athena can utilize, must implement this strategy name into main athena file\n",
    "3. Test Neural Network\n",
    "    1. Run previously generated test data through NN, comparing output with true labels\n",
    "    2. Determine error rate of new athena strategy\n",
    "    3. Compare results to undefended model and PGD-ADT\n",
    "\n",
    "**Important Note:**\n",
    "Our implemetation of this strategy uses 15 randomly selected weak defenses. This is to reduce data collection and training time. With superior computing power, all 72 weak defenses would be uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set was generated using the AE's found in (a); this is all of the AE's included with Athena. A subsample was generated splitting the data from each AE found in (a) into 80% training, 20% testing, using (b). Using (c), we looped through our dataset, generating the raw predictions from each weak defense defined in \"active_wds\" field in (d). Finally, (e) was used to generate the labels for training in a manner which can be used to create an error function for the NN as described in 2A. To transform the test data into a useable form, (f) was used.\n",
    "\n",
    "**Total training samples:** 3600\n",
    "**Total test samples:** 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files:**\n",
    "- (a): src/configs/experiment/data-mnist.json\n",
    "- (b): src/learning_based_strategy/split_data.py\n",
    "- (c): src/learning_based_strategy/collect_raws.py\n",
    "- (d): src/configs/experiment/athena-mnist.json\n",
    "- (e): src/learning_based_strategy/get_training_labels.py\n",
    "- (f): src/learning_based_strategy/get_test_samples.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant Code Snippets for 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Nov 12 17:49:52 2020\n",
    "\n",
    "@author: miles\n",
    "\"\"\"\n",
    "import os\n",
    "from utils.file import load_from_json\n",
    "from utils.data import subsampling\n",
    "import numpy as np\n",
    "\n",
    "data_configs = load_from_json('../configs/experiment/data-mnist.json')\n",
    "\n",
    "path = 'samples/'\n",
    "\n",
    "#get data files, only take the AE type for the filename for matching later\n",
    "data_files = [os.path.join(data_configs.get('dir'), ae_file) for ae_file in data_configs.get('ae_files')]\n",
    "filenames = [ae_file.split('-')[-1].replace('.npy','') for ae_file in data_configs.get('ae_files')]\n",
    "#Get respective label files\n",
    "label_file = os.path.join(data_configs.get('dir'), data_configs.get('label_file'))\n",
    "labels = np.load(label_file)\n",
    "\n",
    "#Subsample from each AE file\n",
    "for file, filename in zip(data_files, filenames):\n",
    "\n",
    "    data = np.load(file)\n",
    "    subsampling(data, labels, 10, 0.2, path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_raw_prediction(trans_configs, model_configs, data_configs, use_logits=False, output_dir='testing'):\n",
    "\n",
    "    #get samples and respective labels\n",
    "    samples = glob.glob('samples/*training_samples*.npy')\n",
    "    labels = glob.glob('samples/*training_labels*.npy')\n",
    "    \n",
    "    #sort based on type of attack\n",
    "    sorted_samples = []\n",
    "    sorted_labels = []\n",
    "    for sample in samples:\n",
    "        pref = sample.split('_training_samples')[0].split('/')[1].replace('.npy','')\n",
    "        sorted_samples.append(sample)\n",
    "        for label in labels:\n",
    "            pref2 = label.split('_training_labels')[0].split('/')[1].replace('.npy','')\n",
    "            if pref == pref2:\n",
    "                sorted_labels.append(label)\n",
    "    \n",
    "    #load data and labels, concatenate into single numpy array for easy looping\n",
    "    samples_dat = [np.load(dat) for dat in sorted_samples]\n",
    "    labels_dat = [np.load(dat) for dat in sorted_labels]\n",
    "    samples_dat = np.concatenate(samples_dat,axis=0)\n",
    "    labels_dat = np.concatenate(labels_dat)\n",
    "    samples = []\n",
    "    labels = []\n",
    "    #Generate raw predictions from each WD for each AE\n",
    "    for i in range(0, len(labels_dat), 100):\n",
    "        raw_preds = athena.predict(x=samples_dat[i], raw=True)\n",
    "        samples.append(raw_preds)\n",
    "        labels.append(labels_dat[i])\n",
    "\n",
    "    #Write out raw predictions to training_data directory\n",
    "    samples = np.concatenate(samples,axis=1)\n",
    "    labels = np.array(labels)\n",
    "    samples_file = os.path.join('training_data/', 'training.npy')\n",
    "    np.save(file=samples_file,arr=samples)\n",
    "    labels_file = os.path.join('training_data/','training_labels.npy')\n",
    "    np.save(file=labels_file,arr=labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From (d), list of weak defenses used in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"active_wds\": [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Nov 15 20:08:08 2020\n",
    "\n",
    "@author: miles\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "file = 'training_data/training_labels.npy'\n",
    "labels = np.load(file)\n",
    "arr = []\n",
    "for label in labels:\n",
    "    temp = [0,0,0,0,0,0,0,0,0,0]\n",
    "    temp[label] = 1;\n",
    "    arr.append(temp)\n",
    "    \n",
    "new_arr = np.array(arr)\n",
    "np.save(file='training_data/labels2D.npy', arr=new_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Nov 15 17:53:22 2020\n",
    "\n",
    "@author: miles\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "samples = glob.glob('samples/*test_samples*.npy')\n",
    "labels = glob.glob('samples/*test_labels*.npy')\n",
    "sorted_samples = []\n",
    "sorted_labels = []\n",
    "for sample in samples:\n",
    "    pref = sample.split('_test_samples')[0].split('/')[1].replace('.npy','')\n",
    "    sorted_samples.append(sample)\n",
    "    for label in labels:\n",
    "        pref2 = label.split('_test_labels')[0].split('/')[1].replace('.npy','')\n",
    "        if pref == pref2:\n",
    "            sorted_labels.append(label)\n",
    "    \n",
    "samples_dat = [np.load(dat) for dat in sorted_samples]\n",
    "labels_dat = [np.load(dat) for dat in sorted_labels]\n",
    "samples_dat = np.concatenate(samples_dat,axis=0)\n",
    "labels_dat = np.concatenate(labels_dat)\n",
    "samples = []\n",
    "labels = []\n",
    "for i in range(0, len(labels_dat), 90):\n",
    "    samples.append(samples_dat[i])\n",
    "    labels.append(labels_dat[i])\n",
    "labels_file = os.path.join('testing/', 'test_labels.npy')\n",
    "samples_file = os.path.join('testing/', 'test_samples.npy')\n",
    "labels = np.array(labels)\n",
    "samples = np.array(samples)\n",
    "np.save(file=labels_file,arr=labels)\n",
    "np.save(file=samples_file,arr=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network has an input layer of shape 15x10, (15 weak defenses were used for this model chosen randomly in order to reduce training time, 10 predictions from each weak defense), two hidden layers and an output layer of 10x1. The output still generates 10 values using softmax, but picks the highest value in a postprocessing phase within Athena. The hidden layers take the input to 150x4, then back down to 150. All activations are relu, except for the final layer which is softmax. \n",
    "**NOTE:** This method should be optimized by using all 72 weak defenses, so the input layer should be 72x10. The network should also be trained on many more than 3600 examples. We did not have the necessary resources to do this in a reasonable amount of time\n",
    "**FILES:**\n",
    "- create NN: src/learning_based_strategy/models/nn.py\n",
    "- NN stored in: src/learning_based_strategy/models/learning-strategy-nn.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.py\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "training_data = np.load('../training_data/training.npy')\n",
    "training_labels = np.load('../training_data/labels2D.npy')\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(150, activation='relu', input_shape=(15 * 10,)))\n",
    "network.add(layers.Dense(600, activation='relu', input_shape=(150 * 4,)))\n",
    "network.add(layers.Dense(150, activation='relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "training_data = np.transpose(training_data, (1,0,2))\n",
    "training_data = training_data.reshape((3600,15*10))\n",
    "\n",
    "network.fit(training_data, training_labels, epochs=10, batch_size=360)\n",
    "network.save('learning-strategy-nn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Test Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the network, we used the data gathered from 1. The trained neural network was implemented as an Athena strategy. When the ensemble is called to make a prediction, those predictions are passed to the trained network. The maximum value of the final output of the network is taken as the final prediction for the ensemble.\n",
    "**Note:** 1000 test samples were used, which is why the shape of the output array is the way it is.\n",
    "\n",
    "**Files:**\n",
    "- implementing learning based strategy: src/learning_based_strategy/models/athena.py\n",
    "- evaluating model: src/learning_based_strategy/eval_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_model.py\n",
    "def evaluate_cnn(trans_configs, model_configs,\n",
    "                 data_configs, save=False, output_dir=None):\n",
    "    \n",
    "    baseline = load_lenet(file=model_configs.get('pgd_trained'), trans_configs=None,\n",
    "                                  use_logits=False, wrap=False)\n",
    "\n",
    "    cnn_configs = model_configs.get('cnn')\n",
    "    file = os.path.join(cnn_configs.get('dir'), cnn_configs.get('um_file'))\n",
    "    undefended = load_lenet(file=file,\n",
    "                            trans_configs=trans_configs.get('configs0'),\n",
    "                            wrap=True)\n",
    "\n",
    "    pool, _ = load_pool(trans_configs=trans_configs,\n",
    "                        model_configs=cnn_configs,\n",
    "                        active_list=True,\n",
    "                        wrap=True)\n",
    "    wds = list(pool.values())\n",
    "    ensemble = Ensemble(classifiers=wds, strategy=ENSEMBLE_STRATEGY.LEARNING.value)\n",
    "    \n",
    "    #Get samples and labels\n",
    "    samples = 'testing/test_samples.npy'\n",
    "    samples = np.load(samples)\n",
    "    \n",
    "    labels = 'testing/test_labels.npy'\n",
    "    labels = np.load(labels)\n",
    "\n",
    "    #make predictions and check error rate for undefended model, ensemble, and PGD-ADT\n",
    "    results = {}\n",
    "    pred_um = undefended.predict(samples)\n",
    "    err_um = error_rate(y_pred=pred_um, y_true=labels)\n",
    "    results['Undefended'] = err_um\n",
    "\n",
    "\n",
    "    pred_ens = ensemble.predict(samples)\n",
    "    err_ens = error_rate(y_pred=pred_ens, y_true=labels)\n",
    "    results['Ensemble'] = err_ens\n",
    "    \n",
    "    pred_bl = baseline.predict(samples)\n",
    "    err_bl = error_rate(y_pred=pred_bl, y_true=labels)\n",
    "    results['PGD-ADT'] = err_bl\n",
    "\n",
    "    res = json.dumps(results)\n",
    "    f = open('results.json', 'w')\n",
    "    f.write(res)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#athena.py\n",
    "learning_strategy = 'models/learning-strategy-nn.h5'\n",
    "def predict_by_predictions(self, raw_predictions):        \n",
    "    \"\"\"\n",
    "        Produce the final prediction given the collection of predictions from the WDs.\n",
    "        :param raw_predictions: numpy array. the collection of predictions from the WDs.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    #Use learning based strategy, get max of predictions\n",
    "    ensemble_preds = None\n",
    "    if self._strategy == ENSEMBLE_STRATEGY.LEARNING.name or self._strategy == ENSEMBLE_STRATEGY.LEARNING.value:\n",
    "        model = keras.models.load_model(learning_strategy)\n",
    "        raw_predictions = np.transpose(raw_predictions, (1,0,2))\n",
    "        raw_predictions = raw_predictions.reshape((1000,150))\n",
    "        ensemble_preds = model.predict(raw_predictions)\n",
    "        return np.argmax(ensemble_preds, axis=1)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#Add strategy to strategies for athena\n",
    "class ENSEMBLE_STRATEGY(Enum):\n",
    "    RD = 0\n",
    "    MV = 1\n",
    "    T2MV = 2\n",
    "    AVEP = 3\n",
    "    AVEL = 4\n",
    "    AVEO = 5\n",
    "    LEARNING = 6\n",
    "\n",
    "    @classmethod\n",
    "    def available_names(cls):\n",
    "        return [\n",
    "            cls.RD.name, cls.MV.name, cls.T2MV.name,\n",
    "            cls.AVEP.name, cls.AVEL.name, cls.AVEO.name, cls.LEARNING.name,\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def available_values(cls):\n",
    "        return [\n",
    "            cls.RD.value, cls.MV.value, cls.T2MV.value,\n",
    "            cls.AVEP.value, cls.AVEL.value, cls.AVEO.value, cls.LEARNING.value,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate of each model on the test examples is shown below. The ensemble corresponds to the model using the learning based strategy.\n",
    "\n",
    "**Files:**\n",
    "- results.json: src/learning_based_strategy/results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"Undefended\": 0.642, \"Ensemble\": 0.039, \"PGD-ADT\": 0.077}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning based strategy has a significantly lower error rate than the other models. It is clear that the predictions of the weak defenses can be used to train a neural network that is able to make even more accurate predictions than just the ensemble alone. However, this dataset was relatively small, only 3600 training examples. Also, the ensemble used to train and test the network was relatively small as well. In order to fully test this model, we would need to generate our own adversarial examples based on the benign samples, and generate them against a fully-defended Athena; all 72 weak defenses active. The network should then be trained to take all 72 weak defenses inputs, and would be trained with at least 8000 examples. This would provide a much more accurate depiction of how effective the learning based strategy would be with this implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final note:** The code above is a rough design, and is specifically tailored to this exact experiment. Further optimized code is certainly possible, however given the time frame and required flexibility due to lack of computing power, (we needed to test frequently and even with a small dataset it took forever), this rough code is what ended up being the final product. We would like to go through and truly implement this as a strategy into Athena, as this small test shows how effective of a strategy this is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributions:\n",
    "- Approach: Miles Ziemer, Max Corbel, Shuge Lei, Safi Hoque\n",
    "- Code: Miles Ziemer, Max Corbel\n",
    "- Data gathering: Miles Ziemer\n",
    "- Testing and interpretation/validation of results: Miles Ziemer, Max Corbel, Shuge Lei Safi Hoque\n",
    "- Report: Miles Ziemer, Max Corbel, Shuge Lei, Safi Hoque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
